{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8Zw0LslvKzP",
        "outputId": "7fe6909f-6edc-4f36-9ed5-21dc9c1ca03c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2ueYuKUvZmZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgHuqBbUwMyI"
      },
      "outputs": [],
      "source": [
        "CH_vcf = pd.read_excel('gdrive/My Drive/CH-tissue/ch_added.xlsx',  header=0)\n",
        "Tissue_vcf = pd.read_excel('gdrive/My Drive/CH-tissue/labels.xlsx', sheet_name='Tumor', header=0)\n",
        "unlabel_vcf = pd.read_excel('gdrive/My Drive/CH-tissue/unlabel.xlsx', sheet_name=0, header=0)\n",
        "unlabel_vcf1 = pd.read_excel('gdrive/My Drive/CH-tissue/unlabel4.xlsx', sheet_name=0, header=0)\n",
        "unlabel_vcf2 = pd.read_excel('gdrive/My Drive/CH-tissue/unlabel5.xlsx', sheet_name=0, header=0)\n",
        "unlabel_vcf3 = pd.read_excel('gdrive/My Drive/CH-tissue/unlabel6.xlsx', sheet_name=0, header=0)\n",
        "unlabel_vcf4 = pd.read_excel('gdrive/My Drive/CH-tissue/unlabel7.xlsx', sheet_name=0, header=0)\n",
        "CH_seq = open('gdrive/My Drive/CH-tissue/ch-seq.txt' , 'r').readlines()\n",
        "tissue_seq = open('gdrive/My Drive/CH-tissue/tissue-seq.txt' , 'r') .readlines()\n",
        "unlabel_seq = open('gdrive/My Drive/CH-tissue/unlabel-seq.txt' , 'r').readlines()\n",
        "unlabel_seq1 = open('gdrive/My Drive/CH-tissue/unlabel4-seq.txt' , 'r').readlines()\n",
        "unlabel_seq2 = open('gdrive/My Drive/CH-tissue/unlabel5-seq.txt' , 'r').readlines()\n",
        "unlabel_seq3 = open('gdrive/My Drive/CH-tissue/unlabel6-seq.txt' , 'r').readlines()\n",
        "unlabel_seq4 = open('gdrive/My Drive/CH-tissue/unlabel7-seq.txt' , 'r').readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cnbl-25u8UC2"
      },
      "outputs": [],
      "source": [
        "Tissue_vcf = Tissue_vcf.rename(columns= {'CHROM':'Chromosome' , 'POSITION': 'Start_Position' , 'REF':'Ref' , 'ALT' : 'Alt'})\n",
        "Tissue_vcf['label'] = 'tissue'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvsBjSpz-zkM"
      },
      "outputs": [],
      "source": [
        "CH_vcf = CH_vcf.rename(columns= {'chromosome':'Chromosome' , 'base_pair_location': 'Start_Position' , 'effect_allele':'Ref' , 'other_allele' : 'Alt'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjL3o90USCrU"
      },
      "outputs": [],
      "source": [
        "glioma_vcf = pd.read_excel('gdrive/My Drive/CH-tissue/glioma.xlsx', sheet_name=0, header=0)\n",
        "glioma_seq = open('gdrive/My Drive/CH-tissue/glioma.txt' , 'r').readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EssGQZEwdwl"
      },
      "outputs": [],
      "source": [
        "def Preprocessing(df, seq, p=3, Label=True):\n",
        "    dic = {'A':0, 'T':1, 'C':2, 'G':3}\n",
        "    if Label:\n",
        "        df = df[['Chromosome', 'Start_Position', 'Alt' , 'Ref','label']]\n",
        "    else:\n",
        "        df = df[['Chromosome', 'Start_Position', 'Alt' , 'Ref']]\n",
        "    for i in range(1,p+1):\n",
        "        df[str(i)+' position'] = 0\n",
        "        df[str(-1*i)+' position'] = 0\n",
        "    Filtered = []\n",
        "    df['Ref'].replace(['-'], ['None'], inplace=True)\n",
        "    df['Alt'].replace(['-'], ['None'], inplace=True)\n",
        "    #df = df.loc[(df['Ref'].isin(n)) & (df['Alt'].isin(n))]\n",
        "\n",
        "    index = 0\n",
        "\n",
        "    for i in range(len(seq)):\n",
        "\n",
        "      if seq[i][0]=='>':\n",
        "        index+=1\n",
        "      elif seq[i][0]!='N':\n",
        "\n",
        "        if len(df['Ref'][index-1])==1 and len(df['Alt'][index-1])==1:\n",
        "            for j in range(1,p+1):\n",
        "              df[str(j)+' position'][index-1] = dic[seq[i][10+j]]\n",
        "              df[str(-1*j)+' position'][index-1] = dic[seq[i][10-j]]\n",
        "            Filtered.append(index-1)\n",
        "\n",
        "    df = df.iloc[Filtered]\n",
        "    df = df.reset_index(drop=True)\n",
        "    df['Ref'].replace(['A','T','C','G'], [0,1,2,3], inplace=True)\n",
        "    df['Alt'].replace(['A','T','C','G'], [0,1,2,3], inplace=True)\n",
        "    if Label:\n",
        "        df['label'].replace(['tissue','CH'], [0,1], inplace=True)\n",
        "\n",
        "    df.loc[df['Chromosome']=='X', ['Chromosome']] = 23\n",
        "    df.loc[df['Chromosome']=='Y', ['Chromosome']] = 24\n",
        "    #df['Start_Position'] = 10*(df['Start_Position'] - df['Start_Position'].mean())/df['Start_Position'].std()\n",
        "    df['Start_Position'] = (df['Start_Position']-100000000)/120000000\n",
        "    return df\n",
        "\n",
        "CH = Preprocessing(CH_vcf , CH_seq)\n",
        "Tissue = Preprocessing(Tissue_vcf , tissue_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbujvrAqSFOW"
      },
      "outputs": [],
      "source": [
        "Tissue = Tissue.sample(12500)\n",
        "Tissue = Tissue.reset_index(drop=True)\n",
        "Tissue.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ID4LXbqT-9H"
      },
      "outputs": [],
      "source": [
        "glioma_vcf['chr'] = glioma_vcf['chr'].map(lambda x: 'chr'+str(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W72hssdZoRNF"
      },
      "outputs": [],
      "source": [
        "def Pre_Process(unlabel_vcf, unlabel_seq):\n",
        "    unlabeled= unlabel_vcf[['chr','pos','ref','alt']]\n",
        "    dic= {}\n",
        "    for i in range(22):\n",
        "        dic['chr'+str(i+1)] = i+1\n",
        "    dic['chrX'] = 23\n",
        "    dic['chrY'] = 24\n",
        "    chromosomes = list(dic.keys())\n",
        "\n",
        "    unlabeled = unlabeled.loc[unlabeled['chr'].isin(chromosomes)]\n",
        "    unlabeled['chr'].replace(chromosomes, list(dic.values()), inplace=True)\n",
        "\n",
        "    unlabels = unlabeled.rename(columns= {'chr':'Chromosome' , 'pos': 'Start_Position' , 'ref':'Ref' , 'alt' : 'Alt'})\n",
        "\n",
        "    unlabels = Preprocessing(unlabels , unlabel_seq , Label=False)\n",
        "    return unlabels\n",
        "\n",
        "unlabels1 = Pre_Process(unlabel_vcf, unlabel_seq)\n",
        "unlabels2 = Pre_Process(unlabel_vcf1, unlabel_seq1)\n",
        "unlabels3 = Pre_Process(unlabel_vcf2, unlabel_seq2)\n",
        "unlabels4 = Pre_Process(unlabel_vcf3, unlabel_seq3)\n",
        "unlabels5 = Pre_Process(unlabel_vcf4, unlabel_seq4)\n",
        "\n",
        "glioma = Pre_Process(glioma_vcf, glioma_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSN4qqpK5_Q5"
      },
      "outputs": [],
      "source": [
        "unlabels = pd.concat([unlabels1, unlabels2, unlabels3, unlabels4, unlabels5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qf_tOuo3U6Ca"
      },
      "outputs": [],
      "source": [
        "total_labels = pd.concat([CH,Tissue]).reset_index(drop = True)\n",
        "test_labels = total_labels.sample(frac=0.1)\n",
        "train_labels = total_labels.drop(test_labels.index)\n",
        "test_labels = test_labels.reset_index(drop=True)\n",
        "train_labels = train_labels.reset_index(drop=True)\n",
        "test_labels.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmtbIV10zyLo"
      },
      "outputs": [],
      "source": [
        "y_train = train_labels.pop(\"label\")\n",
        "y_test = test_labels.pop(\"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psXY5WXV_VkA"
      },
      "outputs": [],
      "source": [
        "test_glioma = glioma.sample(frac=0.2)\n",
        "train_glioma = glioma.drop(test_glioma.index)\n",
        "test_glioma = test_glioma.reset_index(drop=True)\n",
        "train_glioma = train_glioma.reset_index(drop=True)\n",
        "\n",
        "X_train_unsup_glioma = train_glioma.to_numpy()\n",
        "X_test_unsup_glioma = test_glioma.to_numpy()\n",
        "\n",
        "X_train_unsup_glioma = np.asarray(X_train_unsup_glioma).astype('float32')\n",
        "X_test_unsup_glioma = np.asarray(X_test_unsup_glioma).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOK2_UMzYZsZ"
      },
      "outputs": [],
      "source": [
        "X_train = train_labels.to_numpy()\n",
        "X_test = test_labels.to_numpy()\n",
        "\n",
        "X_train = np.asarray(X_train).astype('float32')\n",
        "X_test = np.asarray(X_test).astype('float32')\n",
        "\n",
        "unlabels = pd.concat([train_labels, unlabels])\n",
        "test_unlabels = unlabels.sample(frac=0.1)\n",
        "train_unlabels = unlabels.drop(test_unlabels.index)\n",
        "test_unlabels = test_unlabels.reset_index(drop=True)\n",
        "train_unlabels = train_unlabels.reset_index(drop=True)\n",
        "\n",
        "X_train_unsup = train_unlabels.to_numpy()\n",
        "X_test_unsup = test_unlabels.to_numpy()\n",
        "\n",
        "X_train_unsup = np.asarray(X_train_unsup).astype('float32')\n",
        "X_test_unsup = np.asarray(X_test_unsup).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAcHvHBM9Lbj"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import BayesianRidge, Ridge, ElasticNet\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
        "from sklearn.neural_network import MLPRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYTtOlpeTD2R"
      },
      "outputs": [],
      "source": [
        "def define_gen(latent_dim, output_dim):\n",
        "  Input_gen = tf.keras.layers.Input(shape=(latent_dim,))\n",
        "  X = tf.keras.layers.Dense(50, activation= tf.keras.layers.LeakyReLU(alpha=0.2))(Input_gen)\n",
        "  X = tf.keras.layers.Dropout(0.2)(X)\n",
        "  X = tf.keras.layers.Dense(40, activation= tf.keras.layers.LeakyReLU(alpha=0.2))(X)\n",
        "  X = tf.keras.layers.Dropout(0.2)(X)\n",
        "  X = tf.keras.layers.Dense(30, activation= tf.keras.layers.LeakyReLU(alpha=0.2))(X)\n",
        "  X = tf.keras.layers.Dropout(0.2)(X)\n",
        "  X = tf.keras.layers.Dense(20, activation= tf.keras.layers.LeakyReLU(alpha=0.2))(X)\n",
        "\n",
        "  Output_gen = tf.keras.layers.Dense(output_dim)(X)\n",
        "  model = tf.keras.models.Model(Input_gen, Output_gen)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbuRThV0sv8W"
      },
      "outputs": [],
      "source": [
        "def define_disc(input_shape):\n",
        "  Input_disc = tf.keras.layers.Input(shape= input_shape)\n",
        "  X = tf.keras.layers.Conv1D(filters=16 , kernel_size=3, activation= tf.keras.layers.LeakyReLU(alpha=0.2))(Input_disc)\n",
        "  X = tf.keras.layers.Conv1D(filters=32 , kernel_size=3, activation= tf.keras.layers.LeakyReLU(alpha=0.2))(X)\n",
        "  X = tf.keras.layers.Conv1D(filters=64 , kernel_size=3, activation= tf.keras.layers.LeakyReLU(alpha=0.2))(X)\n",
        "  X = tf.keras.layers.Conv1D(filters=128 , kernel_size=3, activation= tf.keras.layers.LeakyReLU(alpha=0.2))(X)\n",
        "  Output_disc = tf.keras.layers.Flatten()(X)\n",
        "  #Output_disc = tf.keras.layers.Dense(40)(X)\n",
        "  model= tf.keras.models.Model(Input_disc,Output_disc)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2y6IAGK_Bl-J"
      },
      "outputs": [],
      "source": [
        "def custom_activation(x):\n",
        "    Z_x = tf.keras.backend.sum(tf.keras.backend.exp(x), axis=-1, keepdims=True)\n",
        "    D_x = Z_x /(Z_x+1)\n",
        "    return D_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RnABROBAiub"
      },
      "outputs": [],
      "source": [
        "def define_supdisc(disc, num_classes=2):\n",
        "  disc.trainable = False\n",
        "  model=tf.keras.models.Sequential()\n",
        "  model.add(disc)\n",
        "  model.add(tf.keras.layers.Dense(80, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.Dense(60, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.Dense(40, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.Dense(20, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.Dense(10, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))\n",
        "  model.add(tf.keras.layers.Dense(8, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))\n",
        "  model.add(tf.keras.layers.Dense(6, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))\n",
        "  model.add(tf.keras.layers.Dense(4, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))\n",
        "  model.add(tf.keras.layers.Dense(1, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))\n",
        "  model.add(tf.keras.layers.Activation('sigmoid'))\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.05, beta_1=0.5),\n",
        "                loss=\"binary_crossentropy\",metrics=['AUC',])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQloC_hsAiwc"
      },
      "outputs": [],
      "source": [
        "def define_unsupdisc(disc):\n",
        "  model=tf.keras.models.Sequential()\n",
        "  model.add(disc)\n",
        "  model.add(tf.keras.layers.Dense(80, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.Dense(60, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.Dense(40, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.Dense(20,activation='sigmoid'))\n",
        "  model.add(tf.keras.layers.Dense(10,activation='sigmoid'))\n",
        "  model.add(tf.keras.layers.Dense(5,activation='sigmoid'))\n",
        "  model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(lr=0.05, beta_1=0.5))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naV-THcFAiz9"
      },
      "outputs": [],
      "source": [
        "def define_gan(gen_model, disc_unsup):\n",
        "\tdisc_unsup.trainable = False\n",
        "\tgan_output = disc_unsup(gen_model.output)\n",
        "\tmodel = tf.keras.models.Model(gen_model.input, gan_output)\n",
        "\tmodel.compile(loss='binary_crossentropy',\n",
        "               optimizer=tf.keras.optimizers.Adam(lr=0.01, beta_1=0.5))\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1jxQNNMYCNf"
      },
      "outputs": [],
      "source": [
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\tz_input = np.random.randn(latent_dim * n_samples)\n",
        "\tz_input = z_input.reshape(n_samples, latent_dim)\n",
        "\treturn z_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_II4jbXdYCYf"
      },
      "outputs": [],
      "source": [
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "\tz_input = generate_latent_points(latent_dim, n_samples)\n",
        "\tfake_images = generator.predict(z_input)\n",
        "\ty = np.zeros((n_samples, 1))\n",
        "\treturn fake_images, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8WSgtQ87arh"
      },
      "outputs": [],
      "source": [
        "def generate_unlabeled_samples(X_unsup, n_samples, batch_size):\n",
        "  ix = np.random.randint(0, X_unsup.shape[0], n_samples*batch_size)\n",
        "  X = X_unsup[ix]\n",
        "  return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oe8C_WTWy88_"
      },
      "outputs": [],
      "source": [
        "def generate_labeled_samples(X_sup, y_sup, n_samples, batch_size):\n",
        "  ix = np.random.randint(0, X_sup.shape[0], n_samples*batch_size)\n",
        "  X = X_sup[ix]\n",
        "  y = y_sup[ix]\n",
        "  return [X, y]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGGE8pN9NsXk"
      },
      "outputs": [],
      "source": [
        "def train(disc_unsup, disc_sup, gan_model, gen_model, X_train_unsup, X_test_unsup, X_train, y_train, X_test, y_test, latent_dim, num_steps, batch_size):\n",
        "  history_sup=[]\n",
        "  history_sup_train=[]\n",
        "\n",
        "  n_samples = (X_train_unsup.shape[0]//batch_size)\n",
        "\n",
        "  #Unsupervised training\n",
        "  for i in range(num_steps):\n",
        "\n",
        "      X_fake, y_fake = generate_fake_samples(gen_model, latent_dim, X_test_unsup.shape[0])\n",
        "      y_real =  np.ones(shape=(X_test_unsup.shape[0],1))\n",
        "      d_loss_real = disc_unsup.test_on_batch(X_test_unsup.reshape(X_test_unsup.shape[0],-1,1), y_real)\n",
        "      d_loss_fake = disc_unsup.test_on_batch(X_fake.reshape(X_test_unsup.shape[0],-1,1), y_fake)\n",
        "      X_gan, y_gan = generate_latent_points(latent_dim, X_test_unsup.shape[0]),np.ones((X_test_unsup.shape[0], 1))\n",
        "      gan_loss = gan_model.test_on_batch(X_gan, y_gan)\n",
        "\n",
        "      print('test-unsupervise>%d, d[%.3f,%.3f], g[%.3f]' % (i+1, d_loss_real, d_loss_fake, gan_loss))\n",
        "\n",
        "      X_fake, y_fake = generate_fake_samples(gen_model, latent_dim, X_trian_unsup.shape[0])\n",
        "      y_real =  np.ones(shape=(X_train_unsup.shape[0],1))\n",
        "      d_loss_real = disc_unsup.test_on_batch(X_train_unsup.reshape(X_train_unsup.shape[0],-1,1), y_real)\n",
        "      d_loss_fake = disc_unsup.test_on_batch(X_fake.reshape(X_train_unsup.shape[0],-1,1), y_fake)\n",
        "      X_gan, y_gan = generate_latent_points(latent_dim, X_train_unsup.shape[0]),np.ones((X_train_unsup.shape[0], 1))\n",
        "      gan_loss = gan_model.test_on_batch(X_gan, y_gan)\n",
        "\n",
        "      print('train-unsupervise>%d, d[%.3f,%.3f], g[%.3f]' % (i+1, d_loss_real, d_loss_fake, gan_loss))\n",
        "\n",
        "      X_real = generate_unlabeled_samples(X_train_unsup, n_samples, batch_size)\n",
        "      for j in range(n_samples):\n",
        "        X_fake, y_fake = generate_fake_samples(gen_model, latent_dim, batch_size)\n",
        "        y_real =  np.ones(shape=(batch_size,1))\n",
        "        X_Real = X_real[batch_size*j:batch_size*(j+1)].reshape(batch_size,-1,1)\n",
        "        X_Fake = X_fake.reshape(batch_size,-1,1)\n",
        "        d_loss_real = disc_unsup.train_on_batch(X_Real, y_real)\n",
        "        d_loss_fake = disc_unsup.train_on_batch(X_Fake, y_fake)\n",
        "        X_gan, y_gan = generate_latent_points(latent_dim, batch_size),np.ones((batch_size, 1))\n",
        "        gan_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\n",
        "  # Suoervised traning\n",
        "  for i in range(num_steps):\n",
        "\n",
        "      sup_loss, sup_acc = disc_sup.test_on_batch(X_test.reshape(X_test.shape[0],-1,1), y_test)\n",
        "      history_sup.append(sup_acc)\n",
        "\n",
        "      print('test-supervise>%d, c[%.3f,%.0f]' % (i+1, sup_loss, sup_acc*100))\n",
        "\n",
        "      sup_loss, sup_acc = disc_sup.test_on_batch(X_train.reshape(X_train.shape[0],-1,1), y_train)\n",
        "      history_sup_train.append(sup_acc)\n",
        "\n",
        "      print('train-supervise>%d, c[%.3f,%.0f]' % (i+1, sup_loss, sup_acc*100))\n",
        "\n",
        "      X , y = generate_labeled_samples(X_train, y_train, n_samples, batch_size)\n",
        "      for j in range(n_samples):\n",
        "        X_sup = X[batch_size*j:batch_size*(j+1)].reshape(batch_size,-1,1)\n",
        "        sup_loss, sup_acc = disc_sup.train_on_batch(X_sup, y[batch_size*j:batch_size*(j+1)])\n",
        "\n",
        "  return [history_sup, history_sup_train]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuJvSYxvlFlL"
      },
      "outputs": [],
      "source": [
        "num_steps = 200\n",
        "latent_dim = 50\n",
        "batch_size = 2000\n",
        "disc=define_disc((X_train[0].shape[0],1))\n",
        "disc_sup=define_supdisc(disc)\n",
        "disc_unsup=define_unsupdisc(disc)\n",
        "\n",
        "gen_model = define_gen(latent_dim,10)\n",
        "gan_model = define_gan(gen_model, disc_unsup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6dv9LmRaz5u"
      },
      "outputs": [],
      "source": [
        "[history_sup ,history_sup_train] = train(disc_unsup, disc_sup, gan_model, gen_model, X_train_unsup, X_test_unsup, X_train, y_train, X_test, y_test, latent_dim, 200, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKEtNZKAAEeC"
      },
      "outputs": [],
      "source": [
        "[history_sup2  ,history_sup_train2] = train(disc_unsup, disc_sup, gan_model, gen_model, X_train_unsup_glioma, X_test_unsup_glioma, X_train, y_train, X_test, y_test, latent_dim, 200, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PA-qCc1Jqfr2"
      },
      "outputs": [],
      "source": [
        "font = {\n",
        "        'size'   : 15,\n",
        "        'weight' : 'bold'}\n",
        "plt.rcParams[\"font.family\"] = \"Helvetica\"\n",
        "plt.rc('font', **font)\n",
        "plt.rc('text', usetex=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGQ8tYvyX1Ra"
      },
      "outputs": [],
      "source": [
        "x1 = [i*10 for i in range(1,num_steps+1)]\n",
        "x2 = [i*10 for i in range(1,num_steps+1)]\n",
        "\n",
        "hfont = {'fontname':'Helvetica'}\n",
        "\n",
        "plt.plot(x1, history_sup , c = 'r')\n",
        "plt.plot(x2, history_sup_train , c = '#000000')\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(['test', 'train'])\n",
        "\n",
        "plt.savefig('gdrive/My Drive/modelacc.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5v9Mn0QXJl8w"
      },
      "outputs": [],
      "source": [
        "def ROCcurve(y_label,y_pred):\n",
        "  n=500\n",
        "  x=[]\n",
        "  y=[]\n",
        "  theta=[i/n for i in range(n+1)]\n",
        "  TrueTP = y_label.sum()\n",
        "  TrueFP = len(y_label) - TrueTP\n",
        "  for p in theta:\n",
        "      TP=0\n",
        "      FP=0\n",
        "      for j in range(len(y_pred)):\n",
        "        if y_pred[j]>=p:\n",
        "          if y_label[j]==1:\n",
        "            TP+=1\n",
        "          else:\n",
        "            FP+=1\n",
        "      x.append(FP/TrueFP)\n",
        "      y.append(TP/TrueTP)\n",
        "  return [x,y]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vd1EOAYorlHh",
        "outputId": "5ecae0df-296c-4c48-994b-dd0ddcaa007f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "78/78 [==============================] - 0s 1ms/step\n",
            "701/701 [==============================] - 1s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = disc_sup.predict(X_test)\n",
        "y_pred2 = disc_sup.predict(X_train)\n",
        "\n",
        "[x1,y1]=ROCcurve(y_test,y_pred)\n",
        "[x2,y2]=ROCcurve(y_train,y_pred2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "71b236Ni-4ju"
      },
      "outputs": [],
      "source": [
        "plt.plot(x1, y1 , c = 'r', linewidth = '2.5')\n",
        "plt.plot(x2, y2 , c = '#000000', linewidth = '2.5')\n",
        "\n",
        "plt.title(\"ROC Curve\", fontsize=20)\n",
        "plt.xlabel(\"False Positive Rate\", fontsize=18)\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=18)\n",
        "\n",
        "plt.legend(['test', 'train'])\n",
        "\n",
        "plt.savefig('gdrive/My Drive/ROCglioma.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfC6sjhr9Tcd"
      },
      "outputs": [],
      "source": [
        "model_factory = [\n",
        " MLPRegressor(),\n",
        " BayesianRidge()\n",
        "]\n",
        "\n",
        "colores = ['#000099' ,'#000000' , '#990000' ]\n",
        "\n",
        "from sklearn import metrics\n",
        "I = 0\n",
        "for model in model_factory:\n",
        "  clf = model\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  y_pred[y_pred<0]=0\n",
        "  [x,y] = ROCcurve(y_test, y_pred )\n",
        "  plt.plot(x,y, c = colores[I])\n",
        "  I+=1\n",
        "\n",
        "y_pred = disc_sup.predict(X_test)\n",
        "[x,y]=ROCcurve(y_test,y_pred )\n",
        "plt.plot(x,y , colores[2])\n",
        "plt.legend([\n",
        " 'MLPRegressor',\n",
        " 'BayesianRidge',\n",
        " 'SSGAN'\n",
        "])\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.savefig('gdrive/My Drive/ROC.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZAhCQ7zws0a"
      },
      "outputs": [],
      "source": [
        "def Acc(y_label, y_pred):\n",
        "  C = 0\n",
        "  for Indx in range(len(y_pred)):\n",
        "    if y_pred[Indx]>=0.5 and y_label[Indx]==1:\n",
        "      C+=1\n",
        "    elif y_pred[Indx]<=0.5 and y_label[Indx]==0:\n",
        "      C+=1\n",
        "  return C/len(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3L8kwaoR9J_x"
      },
      "outputs": [],
      "source": [
        "P = [i*0.05 for i in range(7,21)]\n",
        "y1 = []\n",
        "y2 = []\n",
        "y3 = []\n",
        "y4 = []\n",
        "\n",
        "Acc_models = {}\n",
        "Acc_models['p'] = P\n",
        "Acc_models['MLPRegressor'] = []\n",
        "Acc_models['BayesianRidge'] = []\n",
        "Acc_models['Kneighborsregressor'] = []\n",
        "Acc_models['SSGAN'] = []\n",
        "\n",
        "for p in P:\n",
        "  Arr= np.random.uniform(low=0, high=1, size= len(y_train))\n",
        "  X_Train = X_train[Arr<=p,:]\n",
        "  y_Train = y_train[Arr<=p]\n",
        "  y_Train= y_Train.reset_index()\n",
        "  y_Train = y_Train['label']\n",
        "\n",
        "  clf = KNeighborsRegressor()\n",
        "  clf.fit(X_Train,y_Train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  Acc_models['Kneighborsregressor'].append(Acc(y_test,y_pred))\n",
        "\n",
        "  clf = MLPRegressor()\n",
        "  clf.fit(X_Train,y_Train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  Acc_models['MLPRegressor'].append(Acc(y_test,y_pred))\n",
        "\n",
        "  clf = BayesianRidge()\n",
        "  clf.fit(X_Train,y_Train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  Acc_models['BayesianRidge'].append(Acc(y_test,y_pred))\n",
        "\n",
        "  disc=define_disc((X_train[0].shape[0],1))\n",
        "  disc_sup=define_supdisc(disc)\n",
        "  disc_unsup=define_unsupdisc(disc)\n",
        "\n",
        "  gen_model = define_gen(latent_dim,10)\n",
        "  gan_model = define_gan(gen_model, disc_unsup)\n",
        "  train(disc_unsup, disc_sup, gan_model, gen_model, X_train_unsup, X_test_unsup, X_Train, y_Train, X_test, y_test, latent_dim, 100, 1000)\n",
        "  Acc_models['SSGAN'].append(history_sup[-1])\n",
        "\n",
        "\n",
        "colores= ['#000000' , '#500050', '#990000', '#000099']\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(Acc_models['p'], Acc_models['MLPRegressor'], marker = 'o' , c=colores[0])\n",
        "plt.plot(Acc_models['p'], Acc_models['BayesianRidge'], marker = 'o' , c=colores[1])\n",
        "plt.plot(Acc_models['p'], Acc_models['Kneighborsregressor'], marker = 'o' ,  c=colores[2])\n",
        "plt.plot(Acc_models['p'], Acc_models['SSGAN'], marker = 'o' ,  c=colores[3])\n",
        "plt.xlabel(\"%training\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(['MLPRegressor', 'BayesianRidge','Kneighborsregressor','SSGAN'])\n",
        "\n",
        "plt.savefig('gdrive/My Drive/project2/ModelsAcc.png')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}