# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1siReh6FAOv2j87fxy6dhKFfsmFU4TYv3
"""

import numpy as np

def train_unsupervised(disc_unsup, gan_model, gen_model, generate_fake_samples, generate_latent_points, generate_unlabeled_samples, X_train_unsup, X_test_unsup, latent_dim, num_steps, batch_size):

  loss_unsup_test=[]

  n_samples = (X_train_unsup.shape[0]//batch_size)

  #Unsupervised training
  for i in range(num_steps):

      X_fake, y_fake = generate_fake_samples(gen_model, latent_dim, X_test_unsup.shape[0])
      y_real =  np.ones(shape=(X_test_unsup.shape[0],1))
      d_loss_real = disc_unsup.test_on_batch(X_test_unsup.reshape(X_test_unsup.shape[0],-1,1), y_real)
      d_loss_fake = disc_unsup.test_on_batch(X_fake.reshape(X_test_unsup.shape[0],-1,1), y_fake)
      X_gan, y_gan = generate_latent_points(latent_dim, X_test_unsup.shape[0]),np.ones((X_test_unsup.shape[0], 1))
      gan_loss = gan_model.test_on_batch(X_gan, y_gan)

      loss_unsup_test.append(gan_loss)

      if i%10 == 0:
          print('test-unsupervise>%d, d[%.3f,%.3f], g[%.3f]' % (i+1, d_loss_real, d_loss_fake, gan_loss))

      X_real = generate_unlabeled_samples(X_train_unsup, n_samples, batch_size)
      for j in range(n_samples):
        X_fake, y_fake = generate_fake_samples(gen_model, latent_dim, batch_size)
        y_real =  np.ones(shape=(batch_size,1))
        X_Real = X_real[batch_size*j:batch_size*(j+1)].reshape(batch_size,-1,1)
        X_Fake = X_fake.reshape(batch_size,-1,1)
        d_loss_real = disc_unsup.train_on_batch(X_Real, y_real)
        d_loss_fake = disc_unsup.train_on_batch(X_Fake, y_fake)
        X_gan, y_gan = generate_latent_points(latent_dim, batch_size),np.ones((batch_size, 1))
        gan_loss = gan_model.train_on_batch(X_gan, y_gan)

  return loss_unsup_test

def train_supervised(disc_sup, generate_labeled_samples, X_train, y_train, X_test, y_test, latent_dim, num_steps, batch_size):

  acc_sup_test=[]

  n_samples = (X_train.shape[0]//batch_size)

  # Supervised traning
  for i in range(num_steps):

      sup_loss, sup_acc = disc_sup.test_on_batch(X_test.reshape(X_test.shape[0],-1,1), y_test)
      acc_sup_test.append(sup_acc)

      if i%10==0:
        print('test-supervise>%d, c[%.3f,%.0f]' % (i+1, sup_loss, sup_acc*100))

      X , y = generate_labeled_samples(X_train, y_train, n_samples, batch_size)
      for j in range(n_samples):
        X_sup = X[batch_size*j:batch_size*(j+1)].reshape(batch_size,-1,1)
        sup_loss, sup_acc = disc_sup.train_on_batch(X_sup, y[batch_size*j:batch_size*(j+1)])

  return acc_sup_test