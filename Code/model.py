# -*- coding: utf-8 -*-
"""SSGAN-model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DAhDgHzKzw6odnzqyZi1s0NOiCg0V2I6
"""

import tensorflow as tf
import numpy as np

def define_gen(latent_dim, output_dim):
  Input_gen = tf.keras.layers.Input(shape=(latent_dim,))
  X = tf.keras.layers.Dense(50, activation= tf.keras.layers.LeakyReLU(alpha=0.2))(Input_gen)
  X = tf.keras.layers.Dropout(0.2)(X)
  X = tf.keras.layers.Dense(40, activation= tf.keras.layers.LeakyReLU(alpha=0.2))(X)
  X = tf.keras.layers.Dropout(0.2)(X)
  X = tf.keras.layers.Dense(30, activation= tf.keras.layers.LeakyReLU(alpha=0.2))(X)
  X = tf.keras.layers.Dropout(0.2)(X)
  X = tf.keras.layers.Dense(20, activation= tf.keras.layers.LeakyReLU(alpha=0.2))(X)

  Output_gen = tf.keras.layers.Dense(output_dim)(X)
  model = tf.keras.models.Model(Input_gen, Output_gen)
  return model

def define_disc(input_shape):
  Input_disc = tf.keras.layers.Input(shape= input_shape)
  X = tf.keras.layers.Conv1D(filters=16 , kernel_size=3, activation= tf.keras.layers.LeakyReLU(alpha=0.2))(Input_disc)
  X = tf.keras.layers.Conv1D(filters=32 , kernel_size=3, activation= tf.keras.layers.LeakyReLU(alpha=0.2))(X)
  X = tf.keras.layers.Conv1D(filters=64 , kernel_size=3, activation= tf.keras.layers.LeakyReLU(alpha=0.2))(X)
  X = tf.keras.layers.Conv1D(filters=128 , kernel_size=3, activation= tf.keras.layers.LeakyReLU(alpha=0.2))(X)
  Output_disc = tf.keras.layers.Flatten()(X)
  model= tf.keras.models.Model(Input_disc,Output_disc)
  return model

def custom_activation(x):
    Z_x = tf.keras.backend.sum(tf.keras.backend.exp(x), axis=-1, keepdims=True)
    D_x = Z_x /(Z_x+1)
    return D_x

def define_supdisc(disc, num_classes=2):
  disc.trainable = False
  model=tf.keras.models.Sequential()
  model.add(disc)
  model.add(tf.keras.layers.Dense(80, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))
  model.add(tf.keras.layers.Dropout(0.2))
  model.add(tf.keras.layers.Dense(60, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))
  model.add(tf.keras.layers.Dropout(0.2))
  model.add(tf.keras.layers.Dense(40, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))
  model.add(tf.keras.layers.Dropout(0.2))
  model.add(tf.keras.layers.Dense(20, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))
  model.add(tf.keras.layers.Dropout(0.2))
  model.add(tf.keras.layers.Dense(10, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))
  model.add(tf.keras.layers.Dense(8, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))
  model.add(tf.keras.layers.Dense(6, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))
  model.add(tf.keras.layers.Dense(4, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))
  model.add(tf.keras.layers.Dense(1, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))
  model.add(tf.keras.layers.Activation('sigmoid'))
  model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.05, beta_1=0.5),
                loss="binary_crossentropy",metrics=['AUC',])
  return model

def define_unsupdisc(disc):
  model=tf.keras.models.Sequential()
  model.add(disc)
  model.add(tf.keras.layers.Dense(80, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))
  model.add(tf.keras.layers.Dropout(0.2))
  model.add(tf.keras.layers.Dense(60, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))
  model.add(tf.keras.layers.Dropout(0.2))
  model.add(tf.keras.layers.Dense(40, activation= tf.keras.layers.LeakyReLU(alpha=0.2)))
  model.add(tf.keras.layers.Dropout(0.2))
  model.add(tf.keras.layers.Dense(20,activation='sigmoid'))
  model.add(tf.keras.layers.Dense(10,activation='sigmoid'))
  model.add(tf.keras.layers.Dense(5,activation='sigmoid'))
  model.add(tf.keras.layers.Dense(1,activation='sigmoid'))
  model.compile(loss='binary_crossentropy',
                optimizer=tf.keras.optimizers.Adam(lr=0.05, beta_1=0.5))
  return model

def define_gan(gen_model, disc_unsup):
	disc_unsup.trainable = False
	gan_output = disc_unsup(gen_model.output)
	model = tf.keras.models.Model(gen_model.input, gan_output)
	model.compile(loss='binary_crossentropy',
               optimizer=tf.keras.optimizers.Adam(lr=0.01, beta_1=0.5))
	return model

def generate_latent_points(latent_dim, n_samples):
	z_input = np.random.randn(latent_dim * n_samples)
	z_input = z_input.reshape(n_samples, latent_dim)
	return z_input

def generate_fake_samples(generator, latent_dim, n_samples):
	z_input = generate_latent_points(latent_dim, n_samples)
	fake_images = generator.predict(z_input)
	y = np.zeros((n_samples, 1))
	return fake_images, y

def generate_unlabeled_samples(X_unsup, n_samples, batch_size):
  ix = np.random.randint(0, X_unsup.shape[0], n_samples*batch_size)
  X = X_unsup[ix]
  return X

def generate_labeled_samples(X_sup, y_sup, n_samples, batch_size):
  ix = np.random.randint(0, X_sup.shape[0], n_samples*batch_size)
  X = X_sup[ix]
  y = y_sup[ix]
  return [X, y]